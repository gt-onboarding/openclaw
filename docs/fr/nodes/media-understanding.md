---
title: ComprÃ©hension des mÃ©dias
summary: "ComprÃ©hension des images/audio/vidÃ©o entrantes (optionnelle) avec solutions de repli via le fournisseur et la CLI"
read_when:
  - Concevoir ou remanier la comprÃ©hension des mÃ©dias
  - Ajuster le prÃ©traitement de l'audio/vidÃ©o/image entrantes
---

<div id="media-understanding-inbound-2026-01-17">
  # ComprÃ©hension des mÃ©dias entrants â€” 2026-01-17
</div>

OpenClaw peut **rÃ©sumer les mÃ©dias entrants** (image/audio/vidÃ©o) avant lâ€™exÃ©cution du pipeline de rÃ©ponse. Il dÃ©tecte automatiquement la disponibilitÃ© dâ€™outils locaux ou de clÃ©s de fournisseur, et peut Ãªtre dÃ©sactivÃ© ou personnalisÃ©. Si la comprÃ©hension est dÃ©sactivÃ©e, les modÃ¨les reÃ§oivent tout de mÃªme les fichiers/URL dâ€™origine comme dâ€™habitude.

<div id="goals">
  ## Objectifs
</div>

* FacultatifÂ : prÃ©â€‘traiter les mÃ©dias entrants en texte court pour un routage plus rapide et une meilleure analyse des commandes.
* PrÃ©server systÃ©matiquement la remise des mÃ©dias originaux au modÃ¨le.
* Prendre en charge les **API des fournisseurs** et les **solutions de repli via la CLI**.
* Permettre lâ€™utilisation de plusieurs modÃ¨les avec bascule ordonnÃ©e (erreur/taille/dÃ©passement de dÃ©lai).

<div id="highlevel-behavior">
  ## Comportement dâ€™ensemble
</div>

1. Collecter les piÃ¨ces jointes entrantes (`MediaPaths`, `MediaUrls`, `MediaTypes`).
2. Pour chaque fonctionnalitÃ© activÃ©e (image/audio/vidÃ©o), sÃ©lectionner les piÃ¨ces jointes selon la stratÃ©gie (par dÃ©fautÂ : **la premiÃ¨re**).
3. Choisir la premiÃ¨re entrÃ©e de modÃ¨le Ã©ligible (taille + fonctionnalitÃ© + authentification).
4. Si un modÃ¨le Ã©choue ou si le mÃ©dia est trop volumineux, **revenir Ã  lâ€™entrÃ©e suivante**.
5. En cas de rÃ©ussiteÂ :
   * `Body` devient un bloc `[Image]`, `[Audio]` ou `[Video]`.
   * Lâ€™audio dÃ©finit `{{Transcript}}`Â ; lâ€™analyse des commandes utilise le texte de lÃ©gende lorsquâ€™il est prÃ©sent,
     sinon la transcription.
   * Les lÃ©gendes sont conservÃ©es comme `User text:` Ã  lâ€™intÃ©rieur du bloc.

Si la comprÃ©hension Ã©choue ou est dÃ©sactivÃ©e, **le flux de rÃ©ponse continue** avec le corps dâ€™origine + les piÃ¨ces jointes.

<div id="config-overview">
  ## AperÃ§u de la configuration
</div>

`tools.media` prend en charge des **modÃ¨les partagÃ©s** ainsi que des surcharges spÃ©cifiques par capacitÃ©Â :

* `tools.media.models`Â : liste de modÃ¨les partagÃ©s (utilisez `capabilities` pour filtrer).
* `tools.media.image` / `tools.media.audio` / `tools.media.video`Â :
  * valeurs par dÃ©faut (`prompt`, `maxChars`, `maxBytes`, `timeoutSeconds`, `language`)
  * surcharges de fournisseur (`baseUrl`, `headers`, `providerOptions`)
  * options audio Deepgram via `tools.media.audio.providerOptions.deepgram`
  * **liste de `models` par capacitÃ©** optionnelle (prioritaire sur les modÃ¨les partagÃ©s)
  * stratÃ©gie `attachments` (`mode`, `maxAttachments`, `prefer`)
  * `scope` (restriction optionnelle par clÃ©s channel/chatType/session)
* `tools.media.concurrency`Â : nombre maximal d&#39;exÃ©cutions simultanÃ©es par capacitÃ© (par dÃ©faut **2**).

```json5
{
  tools: {
    media: {
      models: [ /* shared list */ ],
      image: { /* surcharges optionnelles */ },
      audio: { /* surcharges optionnelles */ },
      video: { /* surcharges optionnelles */ }
    }
  }
}
```

<div id="model-entries">
  ### EntrÃ©es de modÃ¨les
</div>

Chaque entrÃ©e dans `models[]` peut Ãªtre un **fournisseur** ou la **CLI**Â :

```json5
{
  type: "provider",        // default if omitted
  provider: "openai",
  model: "gpt-5.2",
  prompt: "Describe the image in <= 500 chars.",
  maxChars: 500,
  maxBytes: 10485760,
  timeoutSeconds: 60,
  capabilities: ["image"], // optionnel, utilisÃ© pour les entrÃ©es multimodales
  profile: "vision-profile",
  preferredProfile: "vision-fallback"
}
```

```json5
{
  type: "cli",
  command: "gemini",
  args: [
    "-m",
    "gemini-3-flash",
    "--allowed-tools",
    "read_file",
    "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters."
  ],
  maxChars: 500,
  maxBytes: 52428800,
  timeoutSeconds: 120,
  capabilities: ["video", "image"]
}
```

Les modÃ¨les CLI peuvent Ã©galement utiliserÂ :

* `{{MediaDir}}` (rÃ©pertoire contenant le fichier multimÃ©dia)
* `{{OutputDir}}` (rÃ©pertoire temporaire crÃ©Ã© pour cette exÃ©cution)
* `{{OutputBase}}` (chemin de base du fichier temporaire, sans extension)

<div id="defaults-and-limits">
  ## Valeurs par dÃ©faut et limites
</div>

Valeurs par dÃ©faut recommandÃ©esÂ :

* `maxChars`Â : **500** pour lâ€™image/vidÃ©o (court, adaptÃ© aux commandes)
* `maxChars`Â : **non dÃ©fini** pour lâ€™audio (transcription complÃ¨te, sauf si vous imposez une limite)
* `maxBytes`Â :
  * imageÂ : **10MB**
  * audioÂ : **20MB**
  * vidÃ©oÂ : **50MB**

RÃ¨glesÂ :

* Si le mÃ©dia dÃ©passe `maxBytes`, ce modÃ¨le est ignorÃ© et **le modÃ¨le suivant est utilisÃ©**.
* Si le modÃ¨le renvoie plus que `maxChars`, la sortie est tronquÃ©e.
* `prompt` a par dÃ©faut pour valeur une simple invite Â«Â Describe the {media}.Â Â», complÃ©tÃ©e par lâ€™indication `maxChars` (image/vidÃ©o uniquement).
* Si `<capability>.enabled: true` mais quâ€™aucun modÃ¨le nâ€™est configurÃ©, OpenClaw essaie le
  **modÃ¨le de rÃ©ponse actif** lorsque son fournisseur prend en charge cette capacitÃ©.

<div id="auto-detect-media-understanding-default">
  ### DÃ©tection automatique de la comprÃ©hension des mÃ©dias (par dÃ©faut)
</div>

Si `tools.media.<capability>.enabled` nâ€™est **pas** rÃ©glÃ© sur `false` et que vous
nâ€™avez pas configurÃ© de modÃ¨les, OpenClaw effectue une dÃ©tection automatique dans cet ordre
et **sâ€™arrÃªte Ã  la premiÃ¨re option fonctionnelle**Â :

1. **CLI locaux** (audio uniquementÂ ; si installÃ©s)
   * `sherpa-onnx-offline` (requiert `SHERPA_ONNX_MODEL_DIR` avec encoder/decoder/joiner/tokens)
   * `whisper-cli` (`whisper-cpp`Â ; utilise `WHISPER_CPP_MODEL` ou le modÃ¨le Â«Â tinyÂ Â» fourni)
   * `whisper` (CLI PythonÂ ; tÃ©lÃ©charge automatiquement les modÃ¨les)
2. **Gemini CLI** (`gemini`) utilisant `read_many_files`
3. **ClÃ©s de fournisseurs**
   * AudioÂ : OpenAI â†’ Groq â†’ Deepgram â†’ Google
   * ImageÂ : OpenAI â†’ Anthropic â†’ Google â†’ MiniMax
   * VidÃ©oÂ : Google

Pour dÃ©sactiver la dÃ©tection automatique, dÃ©finissezÂ :

```json5
{
  tools: {
    media: {
      audio: {
        enabled: false
      }
    }
  }
}
```

RemarqueÂ : la dÃ©tection de lâ€™exÃ©cutable est effectuÃ©e au mieux sur macOS/Linux/WindowsÂ ; assurez-vous que la CLI est prÃ©sente dans le `PATH` (nous dÃ©veloppons le raccourci `~`), ou dÃ©finissez un modÃ¨le CLI explicite avec un chemin complet de la commande.

<div id="capabilities-optional">
  ## CapacitÃ©s (facultatif)
</div>

Si vous dÃ©finissez `capabilities`, lâ€™entrÃ©e ne sâ€™exÃ©cute que pour ces types de mÃ©dia. Pour les listes partagÃ©es, OpenClaw peut infÃ©rer automatiquement des valeurs par dÃ©fautÂ :

* `openai`, `anthropic`, `minimax`Â : **image**
* `google` (Gemini API)Â : **image + audio + vidÃ©o**
* `groq`Â : **audio**
* `deepgram`Â : **audio**

Pour les entrÃ©es CLI, **dÃ©finissez `capabilities` explicitement** pour Ã©viter des correspondances inattendues.
Si vous omettez `capabilities`, lâ€™entrÃ©e est Ã©ligible pour la liste dans laquelle elle apparaÃ®t.

<div id="provider-support-matrix-openclaw-integrations">
  ## Matrice de prise en charge des fournisseurs (intÃ©grations OpenClaw)
</div>

| FonctionnalitÃ© | IntÃ©gration de fournisseur | Remarques |
|----------------|---------------------------|-----------|
| Image | OpenAI / Anthropic / Google / autres via `pi-ai` | Tout modÃ¨le compatible image rÃ©pertoriÃ© dans le registre fonctionne. |
| Audio | OpenAI, Groq, Deepgram, Google | Transcription cÃ´tÃ© fournisseur (Whisper/Deepgram/Gemini). |
| VidÃ©o | Google (API Gemini) | ComprÃ©hension vidÃ©o cÃ´tÃ© fournisseur. |

<div id="recommended-providers">
  ## Fournisseurs recommandÃ©s
</div>

**Image**

* PrivilÃ©giez votre modÃ¨le actif sâ€™il prend en charge les images.
* Bons choix par dÃ©fautÂ : `openai/gpt-5.2`, `anthropic/claude-opus-4-5`, `google/gemini-3-pro-preview`.

**Audio**

* `openai/gpt-4o-mini-transcribe`, `groq/whisper-large-v3-turbo` ou `deepgram/nova-3`.
* Solution de repli en CLIÂ : `whisper-cli` (whisper-cpp) ou `whisper`.
* Configuration DeepgramÂ : [Deepgram (transcription audio)](/fr/providers/deepgram).

**VidÃ©o**

* `google/gemini-3-flash-preview` (rapide), `google/gemini-3-pro-preview` (plus riche).
* Solution de repli en CLIÂ : CLI `gemini` (prend en charge `read_file` sur la vidÃ©o/lâ€™audio).

<div id="attachment-policy">
  ## Politique de gestion des piÃ¨ces jointes
</div>

Le paramÃ¨tre `attachments` par capacitÃ© contrÃ´le quelles piÃ¨ces jointes sont traitÃ©esÂ :

* `mode`Â : `first` (valeur par dÃ©faut) ou `all`
* `maxAttachments`Â : limite le nombre traitÃ© (par dÃ©faut **1**)
* `prefer`Â : `first`, `last`, `path`, `url`

Lorsque `mode: "all"`, les sorties sont Ã©tiquetÃ©es `[Image 1/2]`, `[Audio 2/2]`, etc.

<div id="config-examples">
  ## Exemples de configuration
</div>

<div id="1-shared-models-list-overrides">
  ### 1) Liste partagÃ©e de modÃ¨les + surcharges
</div>

```json5
{
  tools: {
    media: {
      models: [
        { provider: "openai", model: "gpt-5.2", capabilities: ["image"] },
        { provider: "google", model: "gemini-3-flash-preview", capabilities: ["image", "audio", "video"] },
        {
          type: "cli",
          command: "gemini",
          args: [
            "-m",
            "gemini-3-flash",
            "--allowed-tools",
            "read_file",
            "Lisez le mÃ©dia Ã  {{MediaPath}} et dÃ©crivez-le en <= {{MaxChars}} caractÃ¨res."
          ],
          capabilities: ["image", "video"]
        }
      ],
      audio: {
        attachments: { mode: "all", maxAttachments: 2 }
      },
      video: {
        maxChars: 500
      }
    }
  }
}
```

<div id="2-audio-video-only-image-off">
  ### 2) Audio + vidÃ©o uniquement (sans image)
</div>

```json5
{
  tools: {
    media: {
      audio: {
        enabled: true,
        models: [
          { provider: "openai", model: "gpt-4o-mini-transcribe" },
          {
            type: "cli",
            command: "whisper",
            args: ["--model", "base", "{{MediaPath}}"]
          }
        ]
      },
      video: {
        enabled: true,
        maxChars: 500,
        models: [
          { provider: "google", model: "gemini-3-flash-preview" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Read the media at {{MediaPath}} and describe it in <= {{MaxChars}} characters."
            ]
          }
        ]
      }
    }
  }
}
```

<div id="3-optional-image-understanding">
  ### 3) ComprÃ©hension dâ€™images optionnelle
</div>

```json5
{
  tools: {
    media: {
      image: {
        enabled: true,
        maxBytes: 10485760,
        maxChars: 500,
        models: [
          { provider: "openai", model: "gpt-5.2" },
          { provider: "anthropic", model: "claude-opus-4-5" },
          {
            type: "cli",
            command: "gemini",
            args: [
              "-m",
              "gemini-3-flash",
              "--allowed-tools",
              "read_file",
              "Lisez le mÃ©dia Ã  {{MediaPath}} et dÃ©crivez-le en <= {{MaxChars}} caractÃ¨res."
            ]
          }
        ]
      }
    }
  }
}
```

<div id="4-multimodal-single-entry-explicit-capabilities">
  ### 4) Point dâ€™entrÃ©e unique multimodal (capacitÃ©s explicites)
</div>

```json5
{
  tools: {
    media: {
      image: { models: [{ provider: "google", model: "gemini-3-pro-preview", capabilities: ["image", "video", "audio"] }] },
      audio: { models: [{ provider: "google", model: "gemini-3-pro-preview", capabilities: ["image", "video", "audio"] }] },
      video: { models: [{ provider: "google", model: "gemini-3-pro-preview", capabilities: ["image", "video", "audio"] }] }
    }
  }
}
```

<div id="status-output">
  ## Sortie de statut
</div>

Lorsque l&#39;analyse des mÃ©dias est en cours d&#39;exÃ©cution, `/status` inclut une courte ligne rÃ©capitulativeÂ :

```
ğŸ“ Media: image ok (openai/gpt-5.2) Â· audio skipped (maxBytes)
```

Cela affiche les rÃ©sultats par capacitÃ©, ainsi que le fournisseur/modÃ¨le choisi le cas Ã©chÃ©ant.

<div id="notes">
  ## Notes
</div>

* La comprÃ©hension est rÃ©alisÃ©e **au mieux**. Les erreurs n&#39;empÃªchent pas l&#39;envoi de rÃ©ponses.
* Les piÃ¨ces jointes sont toujours envoyÃ©es aux modÃ¨les, mÃªme lorsque la comprÃ©hension est dÃ©sactivÃ©e.
* Utilisez `scope` pour limiter la portÃ©e de la comprÃ©hension (par ex. uniquement dans les messages privÃ©s/DM).

<div id="related-docs">
  ## Documents associÃ©s
</div>

* [Configuration](/fr/gateway/configuration)
* [Prise en charge des images et des mÃ©dias](/fr/nodes/images)